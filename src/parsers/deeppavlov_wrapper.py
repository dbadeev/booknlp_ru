#!/usr/bin/env python3
"""
–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è DeepPavlov (—á–µ—Ä–µ–∑ Modal).

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ä–µ–∂–∏–º–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏:
1. 'razdel' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Razdel –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏
2. 'native' - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä DeepPavlov
"""

import logging
import modal
from typing import List, Dict, Any, Literal

logger = logging.getLogger(__name__)


class DeepPavlovParser:
    """
    –ö–ª–∏–µ–Ω—Ç –¥–ª—è DeepPavlov, –∑–∞–ø—É—â–µ–Ω–Ω–æ–≥–æ –≤ Modal.

    Args:
        tokenizer: 'razdel' –∏–ª–∏ 'native'
            - 'razdel' (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è): –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Razdel –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏
            - 'native': –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø—Ä–æ—Å—Ç–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä DeepPavlov
    """

    def __init__(self, tokenizer: Literal['razdel', 'native'] = 'razdel'):  # –î–û–ë–ê–í–õ–ï–ù –ü–ê–†–ê–ú–ï–¢–†
        self.logger = logging.getLogger(__name__)
        self.tokenizer_type = tokenizer  # –°–û–•–†–ê–ù–Ø–ï–ú –í–´–ë–û–†

        try:
            self.service = modal.Cls.from_name("booknlp-ru-deeppavlov", "DeepPavlovService")()
            self.logger.info(f"Connected to DeepPavlov via Modal (tokenizer: {tokenizer}).")
        except Exception as e:
            self.logger.error(f"Failed to connect to Modal app: {e}")
            raise e

    def parse_text(self, text: str) -> List[List[Dict[str, Any]]]:
        """
        –ü–∞—Ä—Å–∏—Ç —Ç–µ–∫—Å—Ç —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: List[List[Dict]] - —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å —Ç–æ–∫–µ–Ω–∞–º–∏.
        –ü–æ–ª—è: id, form, lemma, upos, xpos, feats, head, deprel, deps, misc, startchar, endchar
        """
        try:
            # –£–°–õ–û–í–ù–´–ô –í–´–ó–û–í –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
            if self.tokenizer_type == 'razdel':
                results = self.service.parse_text.remote(text)
            elif self.tokenizer_type == 'native':
                results = self.service.parse_text_native.remote(text)
            else:
                raise ValueError(f"Unknown tokenizer: {self.tokenizer_type}")

            return results if results else []
        except Exception as e:
            self.logger.error(f"Error during DeepPavlov parsing: {e}")
            raise e

    def parse_batch(self, texts: List[str]) -> List[List[List[Dict[str, Any]]]]:
        """
        –ü–∞—Ä—Å–∏—Ç –±–∞—Ç—á —Ç–µ–∫—Å—Ç–æ–≤ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º.
        """
        try:
            if self.tokenizer_type == 'razdel':
                return self.service.parse_batch.remote(texts)
            elif self.tokenizer_type == 'native':
                # –î–ª—è native - –≤—ã–∑—ã–≤–∞–µ–º parse_text_native –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                return [self.service.parse_text_native.remote(text) for text in texts]
            else:
                raise ValueError(f"Unknown tokenizer: {self.tokenizer_type}")
        except Exception as e:
            self.logger.error(f"Error during DeepPavlov batch parsing: {e}")
            raise e


if __name__ == "__main__":
    import pandas as pd
    import argparse

    logging.basicConfig(level=logging.INFO)

    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser_args = argparse.ArgumentParser(
        description='Test DeepPavlov parser with different tokenizers'
    )
    parser_args.add_argument(
        '--tokenizer',
        type=str,
        choices=['razdel', 'native'],
        default='razdel',
        help='Choose tokenizer: razdel (recommended) or native'
    )
    args = parser_args.parse_args()

    test_text = "–ú–∞–º–∞ –º—ã–ª–∞ —Ä–∞–º—É."

    print(f"{'=' * 60}")
    print(f"üöÄ Testing DeepPavlov with {args.tokenizer.upper()} tokenizer")
    print(f"{'=' * 60}")

    try:
        # –°–æ–∑–¥–∞—ë–º parser —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º
        parser = DeepPavlovParser(tokenizer=args.tokenizer)
        sentences = parser.parse_text(test_text)

        print(f"\nReceived {len(sentences)} sentence(s)")

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
        all_tokens = [token for sent in sentences for token in sent]
        df = pd.DataFrame(all_tokens)

        print(f"\n--- DeepPavlov Joint Parsing ({args.tokenizer}) ---")
        if not df.empty:
            cols = ['id', 'form', 'lemma', 'upos', 'head', 'deprel']
            available_cols = [col for col in cols if col in df.columns]
            print(df[available_cols].to_string(index=False))

            if 'feats' in df.columns:
                print(f"\n--- Morphological Features ---")
                print(df[['form', 'feats']].to_string(index=False))

            # Character offsets —Ç–æ–ª—å–∫–æ –¥–ª—è razdel
            if 'startchar' in df.columns and args.tokenizer == 'razdel':
                print(f"\n--- Character Offsets (Razdel) ---")
                print(df[['form', 'startchar', 'endchar']].to_string(index=False))
        else:
            print("Empty result")

        print(f"\n‚úÖ Test completed!")

    except Exception as e:
        print(f"\n‚ùå Test failed: {e}")
        import traceback

        traceback.print_exc()
