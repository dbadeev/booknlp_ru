#!/usr/bin/env python3.11
"""
–ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç UAS/LAS –º–µ—Ç—Ä–∏–∫ –±–µ–∑ CoNLL-U –ø–∞—Ä—Å–∏–Ω–≥–∞.
–ù–∞–ø—Ä—è–º—É—é —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç gold –∏ pred —Ñ–∞–π–ª—ã.
"""

import sys
from pathlib import Path
from rich.console import Console
from rich.table import Table
import json

console = Console()

ROOT = Path(__file__).resolve().parents[2]
RESULTS_DIR = ROOT / "results" / "benchmarks"
SYNTAGRUS_TEST = ROOT / "data" / "syntagrus" / "ru_syntagrus-ud-test.conllu"
SLOVNET_PRED = RESULTS_DIR / "slovnet_predictions.conllu"


def parse_conllu_simple(filepath: Path) -> list:
    """
    –ü–∞—Ä—Å–∏—Ç—å CoNLL-U —Ñ–∞–π–ª –ø—Ä–æ—Å—Ç—ã–º —Å–ø–æ—Å–æ–±–æ–º (–±–µ–∑ conllu –±–∏–±–ª–∏–æ—Ç–µ–∫–∏).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∫–∞–∂–¥–æ–µ ‚Äî —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤.
    """
    sentences = []
    current_sent = []

    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.rstrip('\n')

            # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏
            if not line or line.startswith('#'):
                if current_sent:
                    sentences.append(current_sent)
                    current_sent = []
                continue

            # –ü–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–æ–∫—É —Ç–æ–∫–µ–Ω–∞
            parts = line.split('\t')
            if len(parts) < 7:
                continue

            token_id = parts[0]
            form = parts[1]
            lemma = parts[2]
            upos = parts[3]
            head = parts[6]
            deprel = parts[7]

            # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—É—Å—Ç—ã–µ —É–∑–ª—ã (id —Ç–∏–ø–∞ '1_1')
            if '-' in token_id or '_' in token_id:
                continue

            try:
                token_id = int(token_id)
                head = int(head)
            except ValueError:
                continue

            current_sent.append({
                'id': token_id,
                'form': form,
                'head': head,
                'deprel': deprel
            })

    # –î–æ–±–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    if current_sent:
        sentences.append(current_sent)

    return sentences


def calculate_metrics(gold_sentences: list, pred_sentences: list) -> dict:
    """–†–∞—Å—á–µ—Ç UAS –∏ LAS –º–µ—Ç—Ä–∏–∫."""
    if len(gold_sentences) != len(pred_sentences):
        console.print(f"‚ö†Ô∏è  –†–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π:")
        console.print(f"   Gold: {len(gold_sentences)}")
        console.print(f"   Pred: {len(pred_sentences)}")
        return {}

    uas_correct = 0
    las_correct = 0
    total_tokens = 0
    errors = 0

    for sent_idx, (gold_sent, pred_sent) in enumerate(zip(gold_sentences, pred_sentences)):
        # –ú–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (–µ—Å–ª–∏ –ø–∞—Ä—Å–µ—Ä –ø—Ä–æ–ø—É—Å—Ç–∏–ª —á—Ç–æ-—Ç–æ)
        if len(gold_sent) != len(pred_sent):
            errors += 1
            continue

        for gold_token, pred_token in zip(gold_sent, pred_sent):
            gold_head = gold_token['head']
            gold_deprel = gold_token['deprel']

            pred_head = pred_token['head']
            pred_deprel = pred_token['deprel']

            total_tokens += 1

            # UAS: –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –≥–æ–ª–æ–≤–Ω–æ–µ —Å–ª–æ–≤–æ
            if pred_head == gold_head:
                uas_correct += 1

                # LAS: –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –≥–æ–ª–æ–≤–Ω–æ–µ —Å–ª–æ–≤–æ –ò –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π deprel
                if pred_deprel == gold_deprel:
                    las_correct += 1

    if total_tokens == 0:
        console.print("‚ö†Ô∏è  –ù–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏")
        return {}

    uas = uas_correct / total_tokens
    las = las_correct / total_tokens

    metrics = {
        "UAS": uas,
        "LAS": las,
        "uas_correct": uas_correct,
        "las_correct": las_correct,
        "total_tokens": total_tokens,
        "sentences_with_errors": errors
    }

    return metrics


def display_results(metrics: dict):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü–µ."""
    if not metrics:
        return

    table = Table(title="üìà Slovnet on SynTagRus-test")
    table.add_column("–ú–µ—Ç—Ä–∏–∫–∞", style="cyan")
    table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="green")

    table.add_row("UAS", f"{metrics['UAS']:.4f} ({metrics['UAS'] * 100:.2f}%)")
    table.add_row("LAS", f"{metrics['LAS']:.4f} ({metrics['LAS'] * 100:.2f}%)")
    table.add_row("–ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö UAS", str(metrics['uas_correct']))
    table.add_row("–ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö LAS", str(metrics['las_correct']))
    table.add_row("–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤", str(metrics['total_tokens']))

    if metrics['sentences_with_errors'] > 0:
        table.add_row("–û—à–∏–±–∫–∏ —Ä–∞–∑–±–æ—Ä–∞", str(metrics['sentences_with_errors']))

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–æ—Å—Ç–æ –≤—ã–≤–æ–¥–∏–º table, –±–µ–∑ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏
    console.print("\n")
    console.print(table)


def save_results(metrics: dict, output_path: Path):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON."""
    results = {
        "parser": "slovnet",
        "dataset": "SynTagRus-test",
        "test_file": "ru_syntagrus-ud-test.conllu",
        "metrics": {
            "UAS": metrics['UAS'],
            "LAS": metrics['LAS']
        },
        "details": {
            "uas_correct": metrics['uas_correct'],
            "las_correct": metrics['las_correct'],
            "total_tokens": metrics['total_tokens']
        }
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    console.print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")


def main():
    console.print("üìä –û—Ü–µ–Ω–∫–∞ Slovnet –Ω–∞ SynTagRus-test\n")

    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–π–ª—ã
    if not SYNTAGRUS_TEST.exists():
        console.print(f"‚ùå {SYNTAGRUS_TEST} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        sys.exit(1)

    if not SLOVNET_PRED.exists():
        console.print(f"‚ùå {SLOVNET_PRED} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        sys.exit(1)

    # –ü–∞—Ä—Å–∏—Ç—å —Ñ–∞–π–ª—ã
    console.print("üìÇ –ó–∞–≥—Ä—É–∂–∞—é –∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç (SynTagRus)...")
    gold_sentences = parse_conllu_simple(SYNTAGRUS_TEST)
    console.print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(gold_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n")

    console.print("üìÇ –ó–∞–≥—Ä—É–∂–∞—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (Slovnet)...")
    pred_sentences = parse_conllu_simple(SLOVNET_PRED)
    console.print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(pred_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n")

    # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
    console.print("üî¢ –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫...\n")
    metrics = calculate_metrics(gold_sentences, pred_sentences)

    if not metrics:
        console.print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏")
        sys.exit(1)

    # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    display_results(metrics)

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results_file = RESULTS_DIR / "slovnet_metrics_simple.json"
    save_results(metrics, results_file)

    console.print(f"\n‚ú® –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


if __name__ == "__main__":
    main()
