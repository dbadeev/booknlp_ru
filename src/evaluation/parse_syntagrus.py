#!/usr/bin/env python3.11
"""
–ó–∞–ø—É—Å–∫ Slovnet –Ω–∞ SynTagRus test set.
–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ CoNLL-U —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏.
"""

import sys
from pathlib import Path
from typing import List, Dict
from rich.console import Console
from rich.progress import Progress
import conllu

# –ò–º–ø–æ—Ä—Ç—ã Natasha/Slovnet - –ü–†–ê–í–ò–õ–¨–ù–´–ô API
from natasha import (
    Segmenter,
    NewsEmbedding,
    NewsMorphTagger,
    NewsSyntaxParser,
    Doc
)

console = Console()

ROOT = Path(__file__).resolve().parents[2]
DATA_DIR = ROOT / "data"
SYNTAGRUS_DIR = DATA_DIR / "syntagrus"
RESULTS_DIR = ROOT / "results" / "benchmarks"
RESULTS_DIR.mkdir(parents=True, exist_ok=True)

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
SYNTAGRUS_TEST = SYNTAGRUS_DIR / "ru_syntagrus-ud-test.conllu"
SLOVNET_OUTPUT = RESULTS_DIR / "slovnet_predictions.conllu"


def load_syntagrus_sentences(conllu_path: Path) -> List[conllu.models.TokenList]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ SynTagRus."""
    console.print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞—é SynTagRus –∏–∑ {conllu_path}...")

    with open(conllu_path, 'r', encoding='utf-8') as f:
        sentences = conllu.parse(f.read())

    console.print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n")
    return sentences


def run_slovnet_parser(sentences: List[conllu.models.TokenList]) -> List[conllu.models.TokenList]:
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å Slovnet –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö."""
    console.print("üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Slovnet...")

    # –í–ê–ñ–ù–û: –°–Ω–∞—á–∞–ª–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏, –ø–æ—Ç–æ–º –ø–∞—Ä—Å–µ—Ä—ã
    segmenter = Segmenter()
    emb = NewsEmbedding()
    morph_tagger = NewsMorphTagger(emb)
    syntax_parser = NewsSyntaxParser(emb)

    console.print("‚úÖ Slovnet –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\n")

    predictions = []
    errors = 0

    with Progress() as progress:
        task = progress.add_task(
            "[cyan]–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π...",
            total=len(sentences)
        )

        for gold_sent in sentences:
            # –ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            text = gold_sent.metadata.get('text', '')

            if not text:
                # –†–µ–∫–æ–Ω—Å—Ç—Ä—É–∏—Ä–æ–≤–∞—Ç—å –∏–∑ —Ç–æ–∫–µ–Ω–æ–≤ (—Ä–µ–¥–∫–æ)
                tokens = [token['form'] for token in gold_sent if isinstance(token['id'], int)]
                text = ' '.join(tokens)

            try:
                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Doc API Natasha
                doc = Doc(text)
                doc.segment(segmenter)
                doc.tag_morph(morph_tagger)
                doc.parse_syntax(syntax_parser)

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ CoNLL-U
                pred_sent = _slovnet_to_conllu(doc, gold_sent)
                predictions.append(pred_sent)

            except Exception as e:
                errors += 1
                # –ù–∞ –æ—à–∏–±–∫—É –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–æ–ª–æ—Ç–æ–π standard (fallback)
                predictions.append(gold_sent)

            progress.update(task, advance=1)

    if errors > 0:
        console.print(f"\n‚ö†Ô∏è  –û—à–∏–±–æ–∫ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {errors}/{len(sentences)}")
    else:
        console.print("")

    return predictions


def _slovnet_to_conllu(doc, gold_sent: conllu.models.TokenList) -> conllu.models.TokenList:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å Natasha Doc –≤ CoNLL-U —Ñ–æ—Ä–º–∞—Ç.
    –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —É–∑–ª—ã (empty nodes) –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è.
    """
    pred_tokens = []

    # –ù–∞—Ç–∞—à–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–∫–µ–Ω—ã —Å id, pos, lemma, feats, head_id, rel
    token_id_map = {}  # –ú–∞–ø–ø–∏–Ω–≥: old_id -> new_id (–±–µ–∑ –ø—É—Å—Ç—ã—Ö —É–∑–ª–æ–≤)

    for old_idx, token in enumerate(doc.tokens, 1):
        # –ò–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ Natasha —Ç–æ–∫–µ–Ω–∞
        form = token.text
        lemma = form.lower()

        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –∏–∑ doc.tokens[idx]
        pos = getattr(token, 'pos', 'X')
        feats = getattr(token, 'feats', None)

        # –°–∏–Ω—Ç–∞–∫—Å–∏—Å
        head_id = getattr(token, 'head_id', None)
        rel = getattr(token, 'rel', 'root')

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å head_id –≤ —á–∏—Å–ª–æ
        head = _parse_head_id(head_id) if head_id else 0

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å feats
        feats_dict = _parse_feats(feats) if feats else None

        # –ù–æ–≤—ã–π ID (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π)
        new_id = len(pred_tokens) + 1
        token_id_map[old_idx] = new_id

        # –°–æ–∑–¥–∞—Ç—å CoNLL-U —Ç–æ–∫–µ–Ω
        conllu_token = {
            'id': new_id,
            'form': form,
            'lemma': lemma,
            'upos': pos if pos else 'X',
            'xpos': None,
            'feats': feats_dict,
            'head': head,  # –ü–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π head, –ø–æ—Ç–æ–º –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ–º
            'deprel': rel if rel else 'root',
            'deps': None,
            'misc': None,
        }
        pred_tokens.append(conllu_token)

    # –ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å heads —Å —É—á–µ—Ç–æ–º –º–∞–ø–ø–∏–Ω–≥–∞
    for token in pred_tokens:
        old_head = token['head']
        if old_head in token_id_map:
            token['head'] = token_id_map[old_head]
        elif old_head == 0:
            token['head'] = 0  # root
        else:
            token['head'] = 0  # fallback

    # –°–æ–∑–¥–∞—Ç—å CoNLL-U TokenList —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    pred_sent = conllu.models.TokenList(pred_tokens)
    pred_sent.metadata = gold_sent.metadata.copy()

    return pred_sent


def _parse_head_id(head_id) -> int:
    """–ü–∞—Ä—Å–∏—Ç—å head_id –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ —Ç–∏–ø–∞ '1_5' (sent_id_token_id)."""
    if not head_id:
        return 0

    if isinstance(head_id, int):
        return head_id

    # –ù–∞—Ç–∞—à–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç "1_5" –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ
    try:
        if '_' in str(head_id):
            # –§–æ—Ä–º–∞—Ç "sent_token", –Ω–∞–º –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ token
            parts = str(head_id).split('_')
            return int(parts[-1]) if len(parts) > 1 else int(parts[0])
        else:
            return int(head_id)
    except ValueError:
        return 0


def _parse_feats(feats) -> Dict[str, str]:
    """–ü–∞—Ä—Å–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ Natasha —Ñ–æ—Ä–º–∞—Ç–∞."""
    if not feats:
        return None

    # –ù–∞—Ç–∞—à–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
    # –ü—Ä–∏–º–µ—Ä: <Anim,Nom,Masc,Sing>
    feats_dict = {}

    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å—Ç—Ä–æ–∫—É –∏ –ø–∞—Ä—Å–∏—Ç—å
        feats_str = str(feats)
        # –ü—Ä–∏–º–µ—Ä–Ω–æ: "<Anim,Nom,Masc,Sing>"
        # –ù–∞–∏–≤–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ (–º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è)
        if feats_str and feats_str.startswith('<') and feats_str.endswith('>'):
            feats_str = feats_str[1:-1]  # –£–±—Ä–∞—Ç—å <>

        # –î–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω—É–∂–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ù–∞—Ç–∞—à–∞
        # –°–µ–π—á–∞—Å –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        return None

    except Exception:
        return None


def save_predictions(predictions: List[conllu.models.TokenList], output_path: Path):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ CoNLL-U —Ñ–æ—Ä–º–∞—Ç."""
    console.print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ {output_path}...")

    with open(output_path, 'w', encoding='utf-8') as f:
        for sent in predictions:
            f.write(sent.serialize())

    console.print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã ({len(predictions)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)\n")


def main():
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ SynTagRus
    if not SYNTAGRUS_TEST.exists():
        console.print(f"‚ùå {SYNTAGRUS_TEST} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        console.print("   –ó–∞–ø—É—Å—Ç–∏: python scripts/download_syntagrus.py")
        sys.exit(1)

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å SynTagRus test set
    sentences = load_syntagrus_sentences(SYNTAGRUS_TEST)

    # –ó–∞–ø—É—Å—Ç–∏—Ç—å Slovnet
    predictions = run_slovnet_parser(sentences)

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    save_predictions(predictions, SLOVNET_OUTPUT)

    console.print(f"‚ú® –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ‚Üí {SLOVNET_OUTPUT}")


if __name__ == "__main__":
    main()
