#!/usr/bin/env python3.11
"""
CoBaLD Parser ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å gold —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π.
"""

import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(ROOT))
sys.path.insert(0, str(ROOT / "src"))

from typing import List
from rich.console import Console
from rich.progress import Progress
from rich.table import Table
import json

console = Console()

DATA_DIR = ROOT / "data"
SYNTAGRUS_DIR = DATA_DIR / "syntagrus"
RESULTS_DIR = ROOT / "results" / "benchmarks"
RESULTS_DIR.mkdir(parents=True, exist_ok=True)

SYNTAGRUS_TEST = SYNTAGRUS_DIR / "ru_syntagrus-ud-test.conllu"
COBALD_OUTPUT = RESULTS_DIR / "cobald_predictions_fixed.conllu"


def load_cobald_model():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å CoBaLD (–±–µ–∑ pipeline)."""
    console.print("üîç –ó–∞–≥—Ä—É–∑–∫–∞ CoBaLD –º–æ–¥–µ–ª–∏...\n")

    try:
        from cobald_parser import CobaldParser

        model_name = "CoBaLD/xlm-roberta-base-cobald-parser-ru"

        console.print(f"üì• –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å –∏–∑ {model_name}...\n")

        model = CobaldParser.from_pretrained(
            model_name,
            trust_remote_code=True
        )
        model.eval()

        console.print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n")
        return model

    except Exception as e:
        console.print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def parse_conllu_with_tokens(filepath: Path, limit: int = None) -> List[dict]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å —Ç–æ–∫–µ–Ω–∞–º–∏ –∏–∑ gold standard."""
    sentences = []
    current_sent = {"text": "", "tokens": []}

    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.rstrip('\n')

            if not line:
                if current_sent["tokens"]:
                    sentences.append(current_sent)
                    current_sent = {"text": "", "tokens": []}

                    if limit and len(sentences) >= limit:
                        break
                continue

            if line.startswith('# text ='):
                current_sent["text"] = line.split('=', 1)[1].strip()
                continue

            if line.startswith('#'):
                continue

            parts = line.split('\t')
            token_id = parts[0]

            # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å range tokens (1-2) –∏ null tokens (1.1)
            if '-' in token_id or '.' in token_id:
                continue

            if len(parts) >= 2:
                current_sent["tokens"].append(parts[1])

    if current_sent["tokens"] and (not limit or len(sentences) < limit):
        sentences.append(current_sent)

    return sentences


def run_cobald_on_gold_tokens(model, sentences: List[dict]) -> List[dict]:
    """
    –ó–∞–ø—É—Å—Ç–∏—Ç—å CoBaLD –Ω–∞ —Ç–æ–∫–µ–Ω–∞—Ö –∏–∑ gold standard.

    –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º gold —Ç–æ–∫–µ–Ω—ã, –∞ –Ω–µ —Ä–µ—Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º.
    """
    console.print(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (gold —Ç–æ–∫–µ–Ω—ã)...\n")

    results = []
    errors = 0

    with Progress() as progress:
        task = progress.add_task(
            "[cyan]–û–±—Ä–∞–±–æ—Ç–∫–∞...",
            total=len(sentences)
        )

        for i, sent in enumerate(sentences, 1):
            try:
                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω—ã –∏–∑ gold
                words_batch = [sent["tokens"]]

                # –ó–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞–ø—Ä—è–º—É—é
                output = model(
                    words=words_batch,
                    inference_mode=True
                )

                # –ò–∑–≤–ª–µ—á—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                result = {
                    "text": sent["text"],
                    "tokens": sent["tokens"],
                    "output": output
                }
                results.append(result)

            except Exception as e:
                errors += 1
                if errors <= 10:  # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 –æ—à–∏–±–æ–∫
                    console.print(f"\n‚ö†Ô∏è  –û—à–∏–±–∫–∞ {i}: {str(e)[:100]}")

                results.append({
                    "text": sent["text"],
                    "tokens": sent["tokens"],
                    "error": str(e)
                })

            progress.update(task, advance=1)

    if errors > 0:
        console.print(f"\n‚ö†Ô∏è  –í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {errors}/{len(sentences)}\n")

    return results


def convert_to_conllu(results: List[dict], model) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CoNLL-U."""
    conllu_lines = []

    for sent_result in results:
        if "error" in sent_result:
            # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –æ—à–∏–±–∫–∞–º–∏
            continue

        lines = [f"# text = {sent_result['text']}"]

        tokens = sent_result["tokens"]
        output = sent_result["output"]

        # –ò–∑–≤–ª–µ—á—å deps_ud (—Å–∏–Ω—Ç–∞–∫—Å–∏—Å)
        if "deps_ud" in output and output["deps_ud"] is not None:
            deps_ud = output["deps_ud"]

            # deps_ud –∏–º–µ–µ—Ç —Ñ–æ—Ä–º–∞—Ç: [batch_idx, from_idx, to_idx, deprel_id]
            # –§–∏–ª—å—Ç—Ä—É–µ–º batch_idx == 0 (–ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –±–∞—Ç—á–µ)
            arcs = deps_ud[deps_ud[:, 0] == 0][:, 1:]  # [from, to, deprel]

            # –°–æ–∑–¥–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å: token_id -> (head, deprel)
            syntax_dict = {}
            for arc in arcs:
                from_idx = int(arc[0])
                to_idx = int(arc[1])
                deprel_id = int(arc[2])

                # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å deprel
                deprel = model.config.vocabulary.get("ud_deprel", {}).get(deprel_id, "_")

                # to_idx ‚Äî —ç—Ç–æ –∏–Ω–¥–µ–∫—Å —Ç–æ–∫–µ–Ω–∞ (–Ω–∞—á–∏–Ω–∞—è —Å 0)
                # head ‚Äî —ç—Ç–æ from_idx (0 = root)
                head = from_idx if from_idx != to_idx else 0
                syntax_dict[to_idx] = (head, deprel)
        else:
            syntax_dict = {}

        # –ó–∞–ø–∏—Å–∞—Ç—å —Ç–æ–∫–µ–Ω—ã
        for idx, token in enumerate(tokens):
            token_id = idx + 1
            head, deprel = syntax_dict.get(idx, (0, "root"))

            # –ë–∞–∑–æ–≤—ã–π CoNLL-U (–±–µ–∑ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏ –∏ —Å–µ–º–∞–Ω—Ç–∏–∫–∏ –ø–æ–∫–∞)
            line = "\t".join([
                str(token_id),  # ID
                token,  # FORM
                "_",  # LEMMA
                "_",  # UPOS
                "_",  # XPOS
                "_",  # FEATS
                str(head),  # HEAD
                deprel,  # DEPREL
                "_",  # DEPS
                "_",  # MISC
                "_",  # DEEPSLOT
                "_"  # SEMCLASS
            ])
            lines.append(line)

        conllu_lines.append("\n".join(lines))

    return "\n\n".join(conllu_lines)


def main():
    console.print("=" * 80)
    console.print("CoBaLD Parser (Fixed - Gold Tokens)".center(80))
    console.print("=" * 80 + "\n")

    console.print("‚ö†Ô∏è  –≠—Ç–∞ –≤–µ—Ä—Å–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–∫–µ–Ω—ã –∏–∑ gold standard\n")
    console.print("   –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –±–µ–Ω—á–º–∞—Ä–∫–æ–º.\n")

    # –†–µ–∂–∏–º
    mode = input("–†–µ–∂–∏–º [1=—Ç–µ—Å—Ç 10, 2=–ø–æ–ª–Ω—ã–π 8800]: ").strip()
    limit = 10 if mode == '1' else None

    if limit:
        console.print("\nüß™ –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º: 10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n")
    else:
        console.print("\nüöÄ –ü–æ–ª–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫\n")

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
    model = load_cobald_model()

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å gold —Ç–æ–∫–µ–Ω–∞–º–∏
    console.print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞—é –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (gold tokens)...")
    sentences = parse_conllu_with_tokens(SYNTAGRUS_TEST, limit=limit)
    console.print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n")

    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥
    results = run_cobald_on_gold_tokens(model, sentences)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ CoNLL-U
    console.print("\nüíæ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ CoNLL-U...")
    conllu_output = convert_to_conllu(results, model)

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
    output_file = COBALD_OUTPUT if not limit else RESULTS_DIR / "cobald_test_fixed.conllu"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(conllu_output)
    console.print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_file.name}\n")

    console.print("‚ú® –ì–æ—Ç–æ–≤–æ!\n")
    console.print(f"–ü—Ä–æ–≤–µ—Ä—å: head {output_file}\n")


if __name__ == "__main__":
    main()
